batch_size = 32
nb_classes = 2
nb_epochs = 1
hidden_units = 100
embedding_vector_length = 32
# load the dataset but only keep the top n words, zero the rest
top_words = 5000
# truncate and pad input sequences
max_review_length = 500
# load the dataset but only keep the top n words, zero the rest
top_words = 5000
# truncate and pad input sequences
max_review_length = 500
act = 'sigmoid'
lstm = 'LSTM3'
eta = 1.2e-5
name = lstm.lower()